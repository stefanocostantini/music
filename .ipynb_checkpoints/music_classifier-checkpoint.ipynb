{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kapre\n",
    "import keras\n",
    "import os\n",
    "import soundfile as sf\n",
    "import time\n",
    "import progressbar\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata to extract labels\n",
    "metadata = pd.read_csv('/data/music/musicnet/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>composer</th>\n",
       "      <th>composition</th>\n",
       "      <th>movement</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>source</th>\n",
       "      <th>transcriber</th>\n",
       "      <th>catalog_name</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1727</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>2. Andante</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1728</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>3. Scherzo: Presto</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1729</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>4. Andantino - Allegretto</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1730</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>5. Allegro giusto</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1733</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Sonata in A major</td>\n",
       "      <td>2. Andantino</td>\n",
       "      <td>Solo Piano</td>\n",
       "      <td>Museopen</td>\n",
       "      <td>Segundo G. Yogore</td>\n",
       "      <td>D959</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  composer               composition                   movement  \\\n",
       "0  1727  Schubert  Piano Quintet in A major                 2. Andante   \n",
       "1  1728  Schubert  Piano Quintet in A major         3. Scherzo: Presto   \n",
       "2  1729  Schubert  Piano Quintet in A major  4. Andantino - Allegretto   \n",
       "3  1730  Schubert  Piano Quintet in A major          5. Allegro giusto   \n",
       "4  1733  Schubert   Piano Sonata in A major               2. Andantino   \n",
       "\n",
       "        ensemble            source                      transcriber  \\\n",
       "0  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "1  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "2  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "3  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "4     Solo Piano          Museopen                Segundo G. Yogore   \n",
       "\n",
       "  catalog_name  seconds  \n",
       "0        OP114      447  \n",
       "1        OP114      251  \n",
       "2        OP114      444  \n",
       "3        OP114      368  \n",
       "4         D959      546  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Schubert', 'Bach', 'Beethoven']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a dictionary id --> composer, which will be used later to set the labels for all sound snippets\n",
    "composers = pd.Series(metadata.composer.values,index=metadata.id).to_dict()\n",
    "examples = [1755, 2211, 2368]\n",
    "[composers.get(example) for example in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset\n",
    "# First we define a function to load the audio snippets and to create the labels\n",
    "def load_audio(path, downsampling_rate, duration_sec, composers):\n",
    "        '''Requires the soundfile package, imported as sf '''\n",
    "        files = os.listdir(path)\n",
    "        message = \"Processing {0} audio files...\".format(len(files))\n",
    "        print(message)\n",
    "        message = \"Downsampling dataset to {0}% (equivalent to {1} audio files).\".format(downsampling_rate*100, int(downsampling_rate * len(files)) )\n",
    "        print(message)\n",
    "        \n",
    "        ds = np.random.choice(files, int(len(files) * downsampling_rate), replace=False)\n",
    "        \n",
    "        # Initialise empty arrays\n",
    "        data = np.zeros((len(ds), 1, 88200))\n",
    "        labels = np.zeros(len(ds), dtype = \"<U10\")\n",
    "        \n",
    "        with progressbar.ProgressBar(max_value=len(ds)) as bar:\n",
    "            \n",
    "            for i, file in enumerate(ds):\n",
    "                # load and process file, then add to array\n",
    "                audio_clip, sr = sf.read(path + file)\n",
    "                audio_clip = audio_clip[:int(sr*duration_sec)]\n",
    "                audio_clip = audio_clip[np.newaxis, :]\n",
    "                data[i, :audio_clip.shape[0],:audio_clip.shape[1]] = audio_clip\n",
    "                audio_clip = None\n",
    "            \n",
    "                # look up label and add to array\n",
    "                file_id = file.split(\"-\")[0]\n",
    "                label = composers[int(file_id)]\n",
    "                labels[i] = label \n",
    "                label = None\n",
    "                bar.update(i)\n",
    "            \n",
    "        return labels, data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (26 of 61596) |                     | Elapsed Time: 0:00:00 ETA:   0:03:58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 61596 audio files...\n",
      "Downsampling dataset to 100% (equivalent to 61596 audio files).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (61596 of 61596) |##################| Elapsed Time: 0:03:52 Time:  0:03:52\n"
     ]
    }
   ],
   "source": [
    "# Load audio files, process them and create dataset and labels\n",
    "labels, data = load_audio(\"/data/music/musicnet/data_chunks/\", 1, 2, composers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('/data/music/data.hdf5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset\": shape (61596, 1, 88200), type \"<f8\">"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f.create_dataset('dataset', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/data/music/data.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = f['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:20000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30798,)\n",
      "(30798, 1, 88200)\n",
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30798, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn labels to categorical (one-hot encoding)\n",
    "labels_pd = pd.DataFrame(labels)\n",
    "onehot = pd.get_dummies(labels_pd)\n",
    "targets = onehot.as_matrix()\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset and labels into training, validation and test data\n",
    "indices = np.random.permutation(data.shape[0])\n",
    "training_test_split = 0.8\n",
    "size = int(len(indices) * training_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12320, 1, 88200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_idx, test_idx = indices[:size], indices[size:]\n",
    "training_data = data[training_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7b44a30d79cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "test_data = data[training_idx,:], data[test_idx,:]\n",
    "training_labels, test_labels = labels[training_idx,:], labels[test_ids,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "data = np.zeros((61596, 1, 88200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_idx, test_idx = indices[:80], indices[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CONTINUE HERE!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model whose first layer is a mel-spectrogram (from Kapre)\n",
    "from keras.models import Sequential\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code inspired by https://github.com/keunwoochoi/kapre\n",
    "input_shape = (1, 88200)\n",
    "sr = 44100\n",
    "\n",
    "model = Sequential()\n",
    "# A mel-spectrogram layer\n",
    "model.add(Melspectrogram(n_dft=512, n_hop=256, input_shape=input_shape,\n",
    "                         padding='same', sr=sr, n_mels=64,\n",
    "                         fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                         return_decibel_melgram=False, trainable_fb=False,\n",
    "                         trainable_kernel=False,\n",
    "                         name='trainable_stft'))\n",
    "# Maybe some additive white noise.\n",
    "model.add(AdditiveNoise(power=0.2))\n",
    "# If you wanna normalise it per-frequency\n",
    "model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "# After this, it's just a usual keras workflow. For example..\n",
    "# Add some layers, e.g., model.add(some convolution layers..)\n",
    "# Compile the model\n",
    "model.compile('adam', 'categorical_crossentropy') # if single-label classification\n",
    "# train it with raw audio sample inputs\n",
    "#x = load_x() # e.g., x.shape = (10000, 6, 44100)\n",
    "#y = load_y() # e.g., y.shape = (10000, 10) if it's 10-class classification\n",
    "# and train it\n",
    "#model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "trainable_stft (Melspectrogr (None, 64, 345, 1)        279616    \n",
      "_________________________________________________________________\n",
      "additive_noise_3 (AdditiveNo (None, 64, 345, 1)        0         \n",
      "_________________________________________________________________\n",
      "normalization2d_2 (Normaliza (None, 64, 345, 1)        0         \n",
      "=================================================================\n",
      "Total params: 279,616\n",
      "Trainable params: 0\n",
      "Non-trainable params: 279,616\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile('adam', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn labels to categorical (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset in training and test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
