{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/joblib/_multiprocessing_helpers.py:38: UserWarning: [Errno 12] Cannot allocate memory.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kapre\n",
    "import keras\n",
    "import os\n",
    "import soundfile as sf\n",
    "import time\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata to extract labels\n",
    "metadata = pd.read_csv('/data/music/musicnet/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>composer</th>\n",
       "      <th>composition</th>\n",
       "      <th>movement</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>source</th>\n",
       "      <th>transcriber</th>\n",
       "      <th>catalog_name</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1727</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>2. Andante</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1728</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>3. Scherzo: Presto</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1729</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>4. Andantino - Allegretto</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1730</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>5. Allegro giusto</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1733</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Sonata in A major</td>\n",
       "      <td>2. Andantino</td>\n",
       "      <td>Solo Piano</td>\n",
       "      <td>Museopen</td>\n",
       "      <td>Segundo G. Yogore</td>\n",
       "      <td>D959</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  composer               composition                   movement  \\\n",
       "0  1727  Schubert  Piano Quintet in A major                 2. Andante   \n",
       "1  1728  Schubert  Piano Quintet in A major         3. Scherzo: Presto   \n",
       "2  1729  Schubert  Piano Quintet in A major  4. Andantino - Allegretto   \n",
       "3  1730  Schubert  Piano Quintet in A major          5. Allegro giusto   \n",
       "4  1733  Schubert   Piano Sonata in A major               2. Andantino   \n",
       "\n",
       "        ensemble            source                      transcriber  \\\n",
       "0  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "1  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "2  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "3  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "4     Solo Piano          Museopen                Segundo G. Yogore   \n",
       "\n",
       "  catalog_name  seconds  \n",
       "0        OP114      447  \n",
       "1        OP114      251  \n",
       "2        OP114      444  \n",
       "3        OP114      368  \n",
       "4         D959      546  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Schubert', 'Bach', 'Beethoven']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a dictionary id --> composer, which will be used later to set the labels for all sound snippets\n",
    "composers = pd.Series(metadata.composer.values,index=metadata.id).to_dict()\n",
    "examples = [1755, 2211, 2368]\n",
    "[composers.get(example) for example in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset\n",
    "# First we define a function to load the audio snippets and to create the labels\n",
    "def load_audio(path, duration_sec, composers):\n",
    "        '''Requires the soundfile package, imported as sf '''\n",
    "        files = os.listdir(path)\n",
    "        message = \"Processing {0} audio files...\".format(len(files))\n",
    "        print(message)\n",
    "        \n",
    "        # Initialise empty arrays\n",
    "        data = np.zeros((len(files), 1, 88200))\n",
    "        labels = np.zeros(len(files), dtype = \"<U10\")\n",
    "        \n",
    "        with progressbar.ProgressBar(max_value=len(files)) as bar:\n",
    "            \n",
    "            for i, file in enumerate(files):\n",
    "                # load and process file, then add to array\n",
    "                audio_clip, sr = sf.read(path + file)\n",
    "                audio_clip = audio_clip[:int(sr*duration_sec)]\n",
    "                audio_clip = audio_clip[np.newaxis, :]\n",
    "                data[i, :audio_clip.shape[0],:audio_clip.shape[1]] = audio_clip                   \n",
    "            \n",
    "                # look up label and add to array\n",
    "                file_id = file.split(\"-\")[0]\n",
    "                label = composers[int(file_id)]\n",
    "                labels[i] = label            \n",
    "                bar.update(i)\n",
    "            \n",
    "        return labels, data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (210 of 61596) |                    | Elapsed Time: 0:00:00 ETA:   0:00:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 61596 audio files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (61596 of 61596) |##################| Elapsed Time: 0:03:18 Time:  0:03:18\n"
     ]
    }
   ],
   "source": [
    "# Load audio files, process them and create dataset and labels\n",
    "labels, data = load_audio(\"/data/music/musicnet/data_chunks/\", 2, composers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61596,)\n",
      "(61596, 1, 88200)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn labels to categorical (one-hot encoding)\n",
    "labels_pd = pd.DataFrame(labels)\n",
    "onehot = pd.get_dummies(labels_pd)\n",
    "targets = onehot.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61596, 10)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset and labels into training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CONTINUE HERE!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model whose first layer is a mel-spectrogram (from Kapre)\n",
    "from keras.models import Sequential\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code inspired by https://github.com/keunwoochoi/kapre\n",
    "input_shape = (1, 88200)\n",
    "sr = 44100\n",
    "\n",
    "model = Sequential()\n",
    "# A mel-spectrogram layer\n",
    "model.add(Melspectrogram(n_dft=512, n_hop=256, input_shape=input_shape,\n",
    "                         padding='same', sr=sr, n_mels=64,\n",
    "                         fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                         return_decibel_melgram=False, trainable_fb=False,\n",
    "                         trainable_kernel=False,\n",
    "                         name='trainable_stft'))\n",
    "# Maybe some additive white noise.\n",
    "model.add(AdditiveNoise(power=0.2))\n",
    "# If you wanna normalise it per-frequency\n",
    "model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "# After this, it's just a usual keras workflow. For example..\n",
    "# Add some layers, e.g., model.add(some convolution layers..)\n",
    "# Compile the model\n",
    "model.compile('adam', 'categorical_crossentropy') # if single-label classification\n",
    "# train it with raw audio sample inputs\n",
    "#x = load_x() # e.g., x.shape = (10000, 6, 44100)\n",
    "#y = load_y() # e.g., y.shape = (10000, 10) if it's 10-class classification\n",
    "# and train it\n",
    "#model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "trainable_stft (Melspectrogr (None, 64, 345, 1)        279616    \n",
      "_________________________________________________________________\n",
      "additive_noise_3 (AdditiveNo (None, 64, 345, 1)        0         \n",
      "_________________________________________________________________\n",
      "normalization2d_2 (Normaliza (None, 64, 345, 1)        0         \n",
      "=================================================================\n",
      "Total params: 279,616\n",
      "Trainable params: 0\n",
      "Non-trainable params: 279,616\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile('adam', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn labels to categorical (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset in training and test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
