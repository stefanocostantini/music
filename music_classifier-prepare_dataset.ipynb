{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kapre\n",
    "import keras\n",
    "import os\n",
    "import soundfile as sf\n",
    "import time\n",
    "import progressbar\n",
    "import gc\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata to extract labels\n",
    "metadata = pd.read_csv('/data/musicnet/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>composer</th>\n",
       "      <th>composition</th>\n",
       "      <th>movement</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>source</th>\n",
       "      <th>transcriber</th>\n",
       "      <th>catalog_name</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1727</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>2. Andante</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1728</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>3. Scherzo: Presto</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1729</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>4. Andantino - Allegretto</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1730</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Quintet in A major</td>\n",
       "      <td>5. Allegro giusto</td>\n",
       "      <td>Piano Quintet</td>\n",
       "      <td>European Archive</td>\n",
       "      <td>http://tirolmusic.blogspot.com/</td>\n",
       "      <td>OP114</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1733</td>\n",
       "      <td>Schubert</td>\n",
       "      <td>Piano Sonata in A major</td>\n",
       "      <td>2. Andantino</td>\n",
       "      <td>Solo Piano</td>\n",
       "      <td>Museopen</td>\n",
       "      <td>Segundo G. Yogore</td>\n",
       "      <td>D959</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  composer               composition                   movement  \\\n",
       "0  1727  Schubert  Piano Quintet in A major                 2. Andante   \n",
       "1  1728  Schubert  Piano Quintet in A major         3. Scherzo: Presto   \n",
       "2  1729  Schubert  Piano Quintet in A major  4. Andantino - Allegretto   \n",
       "3  1730  Schubert  Piano Quintet in A major          5. Allegro giusto   \n",
       "4  1733  Schubert   Piano Sonata in A major               2. Andantino   \n",
       "\n",
       "        ensemble            source                      transcriber  \\\n",
       "0  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "1  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "2  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "3  Piano Quintet  European Archive  http://tirolmusic.blogspot.com/   \n",
       "4     Solo Piano          Museopen                Segundo G. Yogore   \n",
       "\n",
       "  catalog_name  seconds  \n",
       "0        OP114      447  \n",
       "1        OP114      251  \n",
       "2        OP114      444  \n",
       "3        OP114      368  \n",
       "4         D959      546  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Schubert', 'Bach', 'Beethoven']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a dictionary id --> composer, which will be used later to set the labels for all sound snippets\n",
    "composers = pd.Series(metadata.composer.values,index=metadata.id).to_dict()\n",
    "examples = [1755, 2211, 2368]\n",
    "[composers.get(example) for example in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset\n",
    "# First we define a function to load the audio snippets and to create the labels\n",
    "def load_audio(path, downsampling_rate, duration_sec, composers):\n",
    "        '''Requires the soundfile package, imported as sf '''\n",
    "        files = os.listdir(path)\n",
    "        message = \"Processing {0} audio files...\".format(len(files))\n",
    "        print(message)\n",
    "        message = \"Downsampling dataset to {0}% (equivalent to {1} audio files).\".format(downsampling_rate*100, int(downsampling_rate * len(files)) )\n",
    "        print(message)\n",
    "        \n",
    "        ds = np.random.choice(files, int(len(files) * downsampling_rate), replace=False)\n",
    "        \n",
    "        # Initialise empty arrays\n",
    "        data = np.zeros((len(ds), 1, 88200))\n",
    "        labels = np.zeros(len(ds), dtype = \"<U10\")\n",
    "        \n",
    "        with progressbar.ProgressBar(max_value=len(ds)) as bar:\n",
    "            \n",
    "            for i, file in enumerate(ds):\n",
    "                # load and process file, then add to array\n",
    "                audio_clip, sr = sf.read(path + file)\n",
    "                audio_clip = audio_clip[:int(sr*duration_sec)]\n",
    "                audio_clip = audio_clip[np.newaxis, :]\n",
    "                data[i, :audio_clip.shape[0],:audio_clip.shape[1]] = audio_clip\n",
    "                audio_clip = None\n",
    "            \n",
    "                # look up label and add to array\n",
    "                file_id = file.split(\"-\")[0]\n",
    "                label = composers[int(file_id)]\n",
    "                labels[i] = label \n",
    "                label = None\n",
    "                bar.update(i)\n",
    "            \n",
    "        return labels, data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (209 of 39472) |                    | Elapsed Time: 0:00:00 ETA:   0:00:18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 39472 audio files...\n",
      "Downsampling dataset to 100% (equivalent to 39472 audio files).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (39472 of 39472) |##################| Elapsed Time: 0:00:18 Time:  0:00:18\n"
     ]
    }
   ],
   "source": [
    "# CREATE TRAINING DATASET\n",
    "training_labels, training_data = load_audio(\"/data/musicnet/train_chunks/\", 1, 2, composers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39472, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn labels to categorical (one-hot encoding)\n",
    "training_labels_pd = pd.DataFrame(training_labels)\n",
    "training_onehot = pd.get_dummies(training_labels_pd)\n",
    "training_targets = training_onehot.as_matrix()\n",
    "training_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store datasets as hdf5 files\n",
    "train_data = h5py.File('/data/musicnet/hdf5/train_data.hdf5', 'w')\n",
    "train_data.create_dataset('data', data=training_data)\n",
    "train_data.create_dataset('targets', data=training_targets)\n",
    "train_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove variables and release all memory\n",
    "training_data = None\n",
    "training_labels = None\n",
    "training_targets = None\n",
    "train_data = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (34 of 8089) |                      | Elapsed Time: 0:00:00 ETA:   0:00:23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8089 audio files...\n",
      "Downsampling dataset to 100% (equivalent to 8089 audio files).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8089 of 8089) |####################| Elapsed Time: 0:00:27 Time:  0:00:27\n"
     ]
    }
   ],
   "source": [
    "# CREATE VALIDATION DATASET\n",
    "validation_labels, validation_data = load_audio(\"/data/musicnet/val_chunks/\", 1, 2, composers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8089, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn labels to categorical (one-hot encoding)\n",
    "validation_labels_pd = pd.DataFrame(validation_labels)\n",
    "validation_onehot = pd.get_dummies(validation_labels_pd)\n",
    "validation_targets = validation_onehot.as_matrix()\n",
    "validation_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store datasets as hdf5 files\n",
    "val_data = h5py.File('/data/musicnet/hdf5/val_data.hdf5', 'w')\n",
    "val_data.create_dataset('data', data=validation_data)\n",
    "val_data.create_dataset('targets', data=validation_targets)\n",
    "val_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove variables and release all memory\n",
    "validation_data = None\n",
    "validation_labels = None\n",
    "validation_targets = None\n",
    "val_data = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (2 of 8810) |                       | Elapsed Time: 0:00:00 ETA:   0:09:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8810 audio files...\n",
      "Downsampling dataset to 100% (equivalent to 8810 audio files).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8810 of 8810) |####################| Elapsed Time: 0:00:45 Time:  0:00:45\n"
     ]
    }
   ],
   "source": [
    "# CREATE TEST DATASET\n",
    "testing_labels, testing_data = load_audio(\"/data/musicnet/test_chunks/\", 1, 2, composers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8810, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn labels to categorical (one-hot encoding)\n",
    "testing_labels_pd = pd.DataFrame(testing_labels)\n",
    "testing_onehot = pd.get_dummies(testing_labels_pd)\n",
    "testing_targets = testing_onehot.as_matrix()\n",
    "testing_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store datasets as hdf5 files\n",
    "test_data = h5py.File('/data/musicnet/hdf5/test_data.hdf5', 'w')\n",
    "test_data.create_dataset('data', data=testing_data)\n",
    "test_data.create_dataset('targets', data=testing_targets)\n",
    "test_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove variables and release all memory\n",
    "testing_data = None\n",
    "testing_labels = None\n",
    "testing_targets = None\n",
    "test_data = None\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
